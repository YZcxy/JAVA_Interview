# 计算机操作系统知识点

## 操作系统概论

Q：一句话说清什么是操作系统？  
A：计算机操作系统是管理硬件、提供用户交互的软件系统。  

***
Q：操作系统的发展阶段？  
A：一共可以分为三个阶段：  
- 无操作系统阶段：计算机的所有资源都是等待人工去操作，并且一个用户就会独占整台计算机，当用户在进行输入输出的时候，内存和CPU都处于空闲状态，资源利用率很低。  
- 批处理系统阶段：这个阶段计算机就无需等待人工操作，用户会批量导入任务，计算机就可以自动的执行每一个任务，大幅度提升了资源利用率。也是在这个阶段，提出了非常重要的**多道程序设计**。   
- 分时系统阶段：此阶段最重要的就是人际交互设计，前面两个阶段程序在执行过程中，人是没法干预的。分时系统阶段，人机就可以交互了，人可以实时去 调试程序，多个用户也可以共享计算机资源，分时系统也是现在主流的系统。  
***
Q：什么是多道程序设计？  
A：在批处理系统阶段，虽然用户可以批量输入任务，但是计算机同时只能运行一个任务。多道程序设计指的是在计算机内存中同时存放多个程序，并且这多个程序互相不干扰，多个程序在计算机的管理程序下互相穿插运行，以此来提升计算机资源的利用率。  

***
Q：并发和并行的区别？  
A：并发是指宏观上一段时间可以同时运行多个程序；并行则是指同一时刻能运行多条指令。  

***
Q：操作系统的资源管理如何解决物理资源数量不足和合理分配资源这两个问题？  
A：操作系统虚拟机为用户提供了一种简单、清晰、易用、高效的计算机模型。虚拟机的每种资源都是物力资源通过**复用、虚拟和抽象**而得到的产物。  
![resource](https://upload-images.jianshu.io/upload_images/9221252-547bc1ad6a089c7a?imageMogr2/auto-orient/strip|imageView2/2/w/531/format/webp)

***
Q：复用指什么？  
A：复用可以分为两种。  

- 空分复用共享：将资源从“空间”上分割成更小的单位供不同进程使用。在计算机系统中，内存和外存(磁盘)等是空分复用共享的。  
- 时分复用共享：将资源从“时间”上分割成更小的单位供不同进程使用。在计算机系统中，处理器和磁盘机等是时分复用共享的。  
***
Q：虚拟指什么？  
A：对资源进行转化、模拟或整合，把一个物理资源转变成多个逻辑上的对应物，也可以把多个物理资源变成单个逻辑上的对应物，即创建无须共享独占资源的假象，或创建易用且多于实际物理资源的虚拟资源假象，以达到多用户共享一套计算机物理资源的目的。  

***
Q：抽象指什么？  
A：通过创建软件来屏蔽硬件资源的物理特性和实现细节，简化对硬件资源的操作、控制和使用。  
复用和虚拟的主要目标是解决物理资源数量不足的问题，抽象则用于处理系统复杂性，重点解决资源易用性。  
***
Q：共享资源是指什么？  
A：共享是指系统中的资源可以被多个并发的进程共同使用。有两种共享方式：互斥共享和同时共享。  

***
Q：什么是系统调用？  
A：系统调用是操作系统为应用程序的运行提供良好的环境，**内核**提供了一系列具有预定功能的服务**例程**，通过一组称为系统调用(System Call) 的接口呈现给用户。  
**系统调用是应用程序获取操作系统服务的唯一途径。**  

***
Q：什么是操作系统内核？  
A：内核是一组程序模块，提供支持进程并发执行的基本功能，通常驻留于**内核空间**，运行于**内核态**，具有直接访问硬件设备和所有内存空间的权限，是仅有的能够执行特权指令的程序。  
***

## 进程与线程

Q：一句话说清什么是进程？  
A：进程是操作系统进行资源分配和调度的基本单位。  
***
Q：一句话说清什么是线程？  
A：线程是操作系统进行运行调度的最小单位，不拥有资源。  
***
Q：进程的五种状态：
A：创建状态，就绪状态，执行状态，阻塞状态，终止状态。（和线程的五种状态类似）  
![jc](https://static001.geekbang.org/infoq/6e/6e2747e7ebfd72b7b97644eb48f80d03.png)  
***
Q：什么是生产者和消费者问题？  
A：生产者负责生产产品，并放入缓冲区，消费者负责从缓冲区消费。生产者和消费者可以并发执行。对于计算机来说，在微观角度是有问题的，其中的步骤可以分为三步： 
1. 取出数据放到寄存器中，register = count
2. 在 CPU 的寄存器中将 register 加一，表示生产了一个产品(消费类似)
3. 将 register 放回缓冲区 count = register
因为这三步不是原子操作，生产者在执行第二步的时候，消费者可以开始执行第一步，就会导致数据不同步。  
![scz](https://static001.geekbang.org/infoq/25/254b4088861c1cc5d4f7208a67d55753.png)  
***
Q：什么是哲学家进餐问题？   
A：问题描述：有五个哲学家，他们的生活方式是交替的进行思考和进餐，哲学家们共同使用一张圆桌，分别坐在周围的五张椅子上，在圆桌上有五个碗五支筷子。平时哲学家们只进行思考，饥饿时则试图取靠近他们左、右两支筷子，只有两支筷子都被他拿到的时候才能进餐，进餐完毕后，放下筷子继续思考。   
![zxj](https://static001.geekbang.org/infoq/b9/b925cc8277ebbe73d9c8c428c0c037ba.png)  
问题在哪里呢，如果所有哲学家在同时拿起了左边的筷子，那么所有哲学家都在等待右边的筷子，却永远也等不到，最终只能饿死。  
***
Q：什么是临界资源？  
A：临界资源指的是一些虽作为共享资源却又无法同时被多个进程或线程共同访问的共享资源。当有进程使用临街资源时，其它进程必须依据操作系统的同步机制等待占用进程释放该共享资源才可重新竞争使用共享资源。  
***
Q：进程间同步原则是什么？  
A：为了对临界资源进行有效的约束，就提出了进程间同步的四个原则：  
- 空闲让进：资源无占用，允许使用
- 忙则等待：资源被占用，请求进程等待
- 有限等待：保证有限等待时间能够使用资源，避免其它等待的进程僵死
- 让权等待：等待时，进程需让出CPU，也就是进程由执行状态变为阻塞状态，这也是保证CPU可以高效使用的前提
***
Q：进程间同步的方法？  
A：消息队列、共享存储、信号量等。  
***
Q：信号的本质是什么？  
A：软中断信号（signal，又简称为信号）用来通知进程发生了异步事件。**进程之间通过系统调用kill 发送软中断信号来实现信号传递。**内核也可以因为内部事件而给进程发送信号，通知进程发生了某个事件。信号机制除了基本通知功能外，还可以传递附加信息。   
***
Q：进程收到信号如何处理？  
A：有三种方式可以处理：  
1. 类似中断的处理程序，对于需要处理的信号，进程可以指定处理函数，由该函数来处理。  
2. 忽略某个信号，对该信号不做任何处理，就象未发生过一样。
3. 对该信号的处理保留系统的默认值，这种缺省操作，对大部分的信号的缺省操作是使得进程终止。
***
Q：Ctrl + C 操作系统发生了什么？  
A：如下：  
1. 用户按下`Ctrl-C`，这个键盘输入产生一个硬件中断。
2. 如果 CPU 当前正在执行这个进程的代码，则该进程的用户空间代码暂停执行，CPU从用户态切换到内核态处理硬件中断。
3. 终端驱动程序将`Ctrl-C`解释成一个 SIGINT 信号，记在该进程的PCB中（也可以说发送了一个SIGINT信号给该进程）。
4. 当某个时刻要从内核返回到该进程的用户空间代码继续执行之前，首先处理 PCB 中记录的信号，发现有一个 SIGINT 信号待处理，而这个信号的默认处理动作是终止进程，所以直接终止进程而不再返回它的用户空间代码执行。

注意，`Ctrl-C` 产生的信号只能发给前台进程。一个命令后面加个 & 可以放到后台运行，这样Shell不必等待进程结束就可以接受新的命令，启动新的进程。
***
Q：线程间同步的方法？  
A：互斥量、读写锁、自旋锁、条件变量等。  
***
Q：什么是进程调度？  
A：进程调度是指计算机通过决策决定哪个就绪进程可以获得CPU使用权。也就是说，进程调度指的是计算机选择哪一个进程可以使用CPU，前提是这个进程的状态为就绪状态。进程调度可以大致分为两步：    
- 保留旧进程的运行信息，请出旧进程。  
- 选择新进程，准备运行环境并分配CPU。  
***
Q：进程调度的算法有哪些？  
A：大致有四种算法：  
- 先来先服务：在就绪队列中，按照先来先服务的原则，优先选择队列前面的进程进行调度。  
- 短进程优先：调度程序优先选择就绪队列中**估计运行时间**最短的进程。  
- 高优先权优先：进程附带优先权，高优先权优先调度算法使得紧迫的任务可以优先处理。  
- 时间片轮转：按先来先服务的原则排列就绪进程，每次为进程分配一个时间片执行，时间片用完了，不管有没有执行完，都会将这个进程重新的插到队列的尾部。每个进程分配的时间片都是一样的。  
***

## 死锁

Q：一句话说清什么是死锁？  
A：死锁是指两个或两个以上的进程在执行过程中，由于竞争资源或者由于彼此通信而造成的一种阻塞现象，若无外力作用，它们都将无法推进下去。  
***
Q：死锁的产生的原因？  
A：主要有两种原因：  
- 资源不够，导致的竞争资源。  
- 进程的调度顺序不当。
***
Q：死锁产生的必要条件？  
A：有四个必要条件，如果只满足一个或者两个，不会产生死锁。  
- 互斥条件：进程对资源的使用是**排他的**，直接拥有，其他就只能等待。  
- 请求保持条件：进程在至少持有一个资源的情况下，还可以继续申请资源。  
- 不可剥夺条件：资源在未使用完之前，不能被剥夺。  
- 环路等待条件：环形等待，必然条件，没有环形不成死锁。  
***
Q：如何预防死锁？  
A：针对死锁的必要条件，破坏条件的满足即可。  
- 破坏请求保持条件：规定进程一次申请所有资源，不允许在运行期间提出资源请求。  
- 破坏不可剥夺条件：进程请求新资源得不到满足时，释放现在的资源，或者现在的资源可以被剥夺。  
- 破坏环路等待条件：将资源线性排列，必须从前到后逐个申请，就不会出现环形。  
***
Q：什么是银行家算法？   
A：当一个进程申请使用资源的时候，银行家算法通过先**试探**分配给该进程资源，然后通过安全性算法判断分配后的系统是否处于安全状态，若不安全则试探分配作废，让该进程继续等待。  
***

## 内存管理

Q：内存分配的过程有哪几种方式？  
A：一般有三种方式：  
- 单一连续分配：简单的把内存分为系统区和用户区，这是一种过时的分配方式，不再使用。  
- 固定分区分配：内存空间被划分为若干固定大小的区域，每个分区只提供给一个程序使用。  
- 动态分区分配：根据进程实际需要，动态分配内存空间，具体需要一些算法的帮助。  
***
Q：动态分区分配算法有哪些？  
A：常见的有三种算法：  
- 首次适应算法：每次从头部开始查找，一旦找到了合适的空闲内存分区，就进行分配。  
- 最佳适应算法：空闲分区采用容量大小排序，从小容量开始遍历，匹配合适再分配。  
- 快速适应算法：要求有多个空闲区链表，每个空闲区链表存储一种容量的空闲区，可以快速找到合适的内存区域。  
***
Q：什么是虚拟内存？  
A：虚拟内存是操作系统内存管理的关键技术，其目的是为了让物理内存扩充成更大的逻辑内存，从而让程序获得更多的可用内存。  
***
Q：什么是程序的局部性原理？  
A：局部性原理指的是CPU访问存储器时，无论是存取指令还是存取数据，所访问的存储单元都趋于聚集在一个较小的连续区域中。  
正因为有局部性原理：  
- 计算机在加载程序时，无需全部逻辑空间装入内存，装载需要使用的部分即可。  
- 如果发现所使用的内存不在物理内存中，则发出**缺页中断**，发起页面置换，把保存在辅存中的页面置换到物理内存中，这样程序又可以继续运行了。  
- 从用户层面看，程序拥有很大的内存空间。  
***
Q：什么是页式存储管理？  
A：在计算机组成原理中有**字和字块**的概念，字块是相对物理设备的定义(像内存条)。而页面是相对逻辑空间的定义(也就是相对进程空间的定义)。  
页式存储管理会将逻辑空间等分成若干大小的页面，相应也会将物理内存空间分成与页面大小一样的物理块，以页面为单位，把进程空间装进物理内存中分散的物理块。  
***
Q：直接使用页式存储的问题？  
A：通过页式存储管理，就可以把进程的逻辑空间的每一个页面都放在内存的物理块中去，但是我们怎么知道进程的某一个页面分配到哪一个字块中去呢？所以我们需要**页表**来记录进程逻辑空间与物理空间的映射。   
在现代计算机系统中，可以支持非常大的逻辑地址空间(2^32 ~ 2^64)，这样，页表就会变得非常大，要占用非常大的内存空间。比如在一个32位逻辑地址空间的分页系统，规定页面大小为4KB，则每个进程的页表就需要1MB的内存空间。  
***
Q：什么是段式存储管理？  
A：段式存储将逻辑空间分为若干不相等的段(根据实际需求)，所以也需要一个**段表**来记录映射，每个段的长度不一，因此段表多一个属性(段长)。  
***
Q：对比下页式存储和段式存储？  
A：共同点：都是离散地管理进程的逻辑空间。  
不同点：  
- 页是物理单位，段是逻辑单位
- 分页是为了合理利用空间，分段是为了满足用户要求
- 页的大小由硬件固定，段的长度可以动态变化
- 页表信息一维，段表信息二维
***
Q：什么是段页式存储？  
A：结合了页式和段式各自的优点，先将逻辑空间按段式管理分成若干段，然后再把段内空间按页式管理分成若干页。  
![dys](https://static001.geekbang.org/infoq/b5/b5e57f61bc5f11a6c64d0c1d869b3b2e.png)

## 线程同步

Q：线程之间同步常用方法？  
A：常用有四种方法：  
- 互斥量
- 自旋锁
- 条件变量
- 读写锁
***
Q：什么是互斥量？   
A：互斥量是保证当某一个线程在操作临界资源时，它可以阻塞其他线程的访问。互斥量的效果也称为**原子性**。一系列操作要么全部执行完，要么全部不执行，不存在部分执行的情况。就比生产者与消费者模型中，三条指令会全部执行完成才会释放 CPU。  
***
Q：什么是自旋锁？  
A：自旋锁和互斥量的工作原理是一样的，也具有互斥性。但是使用了自旋锁的线程会反复检查锁变量是否可用，如果不可能就会循环反复检查。因此，自旋锁不会让出 CPU，是一种**忙等待状态**。  
***
Q：对比自旋锁和互斥量？  
A：自旋锁非阻塞，互斥量会阻塞。因此，自旋锁避免了进程和线程上下文切换的开销，但是增加了CPU 的开销。如果是单核处理器，建议不要使用自旋锁。如果是多核处理器，根据预计线程等待锁的时间来判断，等待时间短使用自旋锁，等待时间长就使用互斥量。  
***
Q：什么是条件变量？  
A：从自旋锁中其实可以得出经验，当线程需求的条件没有满足时，就没有必要一直去加锁->判断条件不成立->解锁，完全可以让出 CPU 给别的线程。因此有了条件变量，假设此时缓冲区等于0，当生产者生产一个产品时，唤醒可能等待的消费者。假设缓冲区满时，当消费者消费一个产品时，唤醒可能等待的生产者。  
条件变量需要配合互斥量来使用，条件变量解决的是等待的问题。  
***
Q：什么是读写锁？  
A：读写锁允许多个读线程同时读取某一临界资源，而写操作与任何操作都互斥。如果在多读少写的场景就比较适合读写锁；如果只有一个读者，一个写者，那么其实就等价于直接使用互斥量。  

## CPU 缓存模型

Q：为什么CPU需要缓存？  
A：因为现代 CPU 的计算速度，远远高于访问主内存的速度，因此如果没有缓存，CPU 会浪费很多的时间用于等待访问内存。  
***
Q：CPU 的缓存模型什么样子？  
A：目前流行的缓存一般分为三级缓存：  
![](https://img-blog.csdn.net/20160103044115119?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)  

***
Q：什么是时间局部性（Temporal Locality）？  
A：如果一个信息项正在被访问，那么在近期它很可能还会被再次访问。比如循环、递归、方法的反复调用等。

***
Q：什么是空间局部性（Spatial Locality）？  
A：如果一个存储器的位置被引用，那么将来他附近的位置也会被引用。比如顺序执行的代码、连续创建的两个对象、数组等。

***
Q：带有高速缓存的CPU执行计算的流程？  
A：分为如下四步：  

1. 程序以及数据被加载到主内存
2. 指令和数据被加载到CPU的高速缓存
3. CPU执行指令，把结果写到高速缓存
4. 高速缓存中的数据写回主内存
***
Q：CPU Cache 的数据写入？  
A：分为两种情况：  
- 写直达（Write Through）：在这个方法里，写入前会先判断数据是否已经在 CPU Cache 里面了：
  如果数据已经在 Cache 里面，先将数据更新到 Cache 里面，再写入到内存里面；
  如果数据没有在 Cache 里面，就直接把数据更新到内存里面。
- 写回（Write Back）：当发生写操作时，新的数据仅仅被写入 Cache Block 里，只有当修改过的 Cache Block「被替换」时才需要写到内存中，减少了数据写回内存的频率，这样便可以提高系统的性能。
***
Q：什么是缓存行cache line？  
A：cache line是 cache 与内存数据交换的最小单位，根据操作系统一般是 32byte 或 64byte。在MESI 协议中，状态可以是M、E、S、I，地址则是cache line中映射的内存地址，数据则是从内存中读取的数据。  
![](https://img-blog.csdn.net/20160103045621163?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQv/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center)
***
Q：如何解决缓存一致性？  
A：想要同步两个不同核心CPU里面的缓存数据。需要做到下面这 2 点：  
1. 某个 CPU 核心里的 Cache 数据更新时，必须要传播到其他核心的 Cache，这个称为写传播（Wreite Propagation）；
2. 某个 CPU 核心里对数据的操作顺序，必须在其他核心看起来顺序是一样的，这个称为事务的串形化（Transaction Serialization）。
***
Q：什么是总线嗅探？  
A：写传播的原则就是当某个 CPU 核心更新了 Cache 中的数据，要把该事件广播通知到其他核心。最常见实现的方式是总线嗅探（Bus Snooping）。  
CPU 需要每时每刻监听总线上的一切活动，但是不管别的核心的 Cache 是否缓存相同的数据，都需要发出一个广播事件，这无疑会加重总线的负载。  
总线嗅探只是保证了某个 CPU 核心的 Cache 更新数据这个事件能被其他 CPU 核心知道，但是并不能保证事务串形化。于是需要 MESI 缓存一致性协议。
***
Q：什么是多核CPU多级缓存一致性协议？  
A：在多核CPU中，内存中的数据会在多个核心中存在数据副本，某一个核心发生修改操作，就产生了数据不一致的问题。而一致性协议正是用于保证多个CPU cache之间缓存共享数据的一致。  
***
Q：MESI 协议是什么？  
A：MESI协议将 cache line 的状态分成 modify、exclusive、shared、invalid，分别是修改、独占、共享和失效。  
- modify：当前CPU cache拥有最新数据（最新的cache line），其他CPU拥有失效数据（cache line的状态是invalid），虽然当前CPU中的数据和主存是不一致的，但是以当前CPU的数据为准；
- exclusive：只有当前CPU中有数据，其他CPU中没有改数据，当前CPU的数据和主存中的数据是一致的；
- shared：当前CPU和其他CPU中都有共同数据，并且和主存中的数据一致；
- invalid：当前CPU中的数据失效，数据应该从主存中获取，其他CPU中可能有数据也可能无数据，当前CPU中的数据和主存被认为是不一致的；
***
Q：MESI 协议中触发事件？  
A：MESI协议中，每个 cache 的**控制器**不仅知道自己的操作（local read和local write），每个核心的缓存控制器通过监听也知道其他 CPU 中 cache 的操作（remote read和remote write），再确定自己 cache 中共享数据的状态是否需要调整。  
***
Q：状态转换和cache操作？  
A：初始场景：在最初的时候，所有 CPU 中都没有数据，某一个 CPU 发生读操作，此时必然发生cache miss，数据从主存中读取到当前 CPU 的 cache，状态为E（独占，只有当前CPU有数据，且和主存一致），此时如果有其他 CPU 也读取数据，则状态修改为 S（共享，多个 CPU 之间拥有相同数据，并且和主存保持一致），如果其中某一个 CPU 发生数据修改，那么该 CPU 中数据状态修改为M（拥有最新数据，和主存不一致，但是以当前CPU中的为准），其他拥有该数据的核心通过缓存控制器监听到 remote write 行文，然后将自己拥有的数据的 cache line 状态修改为I（失效，和主存中的数据被认为不一致，数据不可用应该重新获取）。
***
Q：MESI优化和他们引入的问题？  
A：缓存的一致性消息传递是要时间的，这就使其切换时会产生延迟。当一个缓存被切换状态时其他缓存收到消息完成各自的切换并且发出回应消息这么一长串的时间中CPU都会等待所有缓存响应完成。可能出现的阻塞都会导致各种各样的性能问题和稳定性问题。  
***
Q：CPU切换状态阻塞解决-存储缓存？  
A：比如你需要修改本地缓存中的一条信息，那么你必须将 I（无效）状态通知到其他拥有该缓存数据的CPU缓存中，并且等待确认。等待确认的过程会阻塞处理器，这会降低处理器的性能。应为这个等待远远比一个指令的执行时间长的多。  
![](https://i0.hdslb.com/bfs/article/40529147595372de19175ddf7e5445f349e3972f.png@1152w_834h.webp)
***
Q：Store Bufferes的作用？  
A：为了避免这种 CPU 运算能力的浪费，Store Bufferes 被引入使用。处理器把它想要写入到主存的值写到缓存，然后继续去处理其他事情。当所有失效确认（Invalidate Acknowledge）都接收到时，数据才会最终被提交。在提交之前 Store Buffer 和 Cache 不一致，则直接从 Store Buffer 中读取，这叫Store Forwarding。

***
Q：为什么需要Memory Barriers？  
A：通过 Store Bufferes 和 Store Forwarding 解决了单个 CPU 执行顺序性和内存可见性问题，但是在全局多 CPU 的环境下，这种内存可见性恐怕就很难保证了。因此需要Memory Barriers。  
***
Q：为什么需要Invalidate Queues？  
A：因为 Store Buffer 本身很小，如果写入变更指向的变量在 CPU 本地缓存中均是 cache miss 的情况下，变更数量超过了 Store Buffer 能承载的容量，CPU 依然需要等待 Store Buffer 排空后才能继续处理。
![](https://s4.51cto.com/oss/202004/21/3b167fb0c6346e65f24ceb7c70740206.jpeg)








